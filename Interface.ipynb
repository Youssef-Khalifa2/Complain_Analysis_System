{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf \n",
    "import snowflake.connector\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import langdetect\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau,TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import export_graphviz\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import streamlit as st "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {0: 'AC', 1: 'AC_DLP', 2: 'Access Control', 3: 'Access Control - Facility Management', 4: 'Access Permission', 5: 'Access Permission - MSA', 6: 'Access Permission - MVD', 7: 'Access Permission - UTC', 8: 'Aluminum', 9: 'Aluminum_DLP', 10: 'Attitude', 11: 'Blacksmith', 12: 'Business proposal', 13: 'CM Office', 14: 'Call Center internal escalation', 15: 'Careers', 16: 'Carpentry', 17: 'Carpentry-DLP', 18: 'Check Collection', 19: 'Check Up Call', 20: 'Cheque Resubmission', 21: 'Civil', 22: 'Civil-DLP', 23: 'Cleaning', 24: 'Clients follow up on their requests within SLA', 25: 'Collection Complaint', 26: 'Common Area enhancement', 27: 'Community Center', 28: 'Community Rules', 29: 'Community Violation', 30: 'Construction', 31: 'Contractors Violation', 32: 'Customer Data update', 33: 'Data Violation', 34: 'Delay Penalty', 35: 'Delivery Cheque Collection Inquiry', 36: 'Design Dispute', 37: 'Dues Inquiries', 38: 'Early Handover Request', 39: 'Electrical', 40: 'Electrical-DLP', 41: 'Elevators', 42: 'Emaar Misr application Feedback/suggestions', 43: 'Emaar Misr application Technical Issue', 44: 'Events', 45: 'Expected Handover Date', 46: 'Extra Parking/Storage', 47: 'FM - Finance', 48: 'Fiber Cable', 49: 'Finance', 50: 'Floor Plan Request- As built / Paint code', 51: 'Follow Up on Email', 52: 'Gas Cylinder', 53: 'General Feedback/Suggestions', 54: 'General Help', 55: 'General Queries', 56: 'Gym', 57: 'Gym issues', 58: 'Handover - Finance', 59: 'Handover Letter Acknowledgment by Customer', 60: 'Handover Request', 61: 'Handover visit Confirmation', 62: 'Insurance Amount Refund', 63: 'Irrigation', 64: 'Lack of Security', 65: 'Landscaping', 66: 'Lost and Found', 67: 'Maintenance Difference', 68: 'Meters', 69: 'Mosque', 70: 'Neighbor Noise', 71: 'Parking Issue', 72: 'Personal Accident', 73: 'Pest Control', 74: 'Physical Fights', 75: 'Plumbing', 76: 'Plumbing-DLP', 77: 'Projects facilities working hours', 78: 'RO- Access Premission', 79: 'RO- Beach Access complains', 80: 'RO- Beach Seating Reservations', 81: 'RO- Cleaning issues', 82: 'RO- Clubhouse Room Reservations', 83: 'RO- Events Issues', 84: 'RO- Events Parking Issues', 85: 'RO- Food And Beverage Quailty issues', 86: 'RO- General Inquires / Suggestions', 87: 'RO- Gym- Lack of Equipment', 88: 'RO- Gym- Qulaity of Equipment', 89: 'RO- Kids Area - Lack of Equipment/ Activities', 90: 'RO- Kids Area - Lack of Supervision', 91: 'RO- Lack of Safety precautions', 92: 'RO- Landscape Issues', 93: 'RO- Maintenance', 94: 'RO- Noise - Loud Music', 95: 'RO- Noise - Operation Staff', 96: 'RO- Noise - Private workers', 97: 'RO- Operating Premission', 98: 'RO- Parking Issues', 99: 'RO- Retail Operation Staff -Attuitde/Performance', 100: 'RO- Rules Violation', 101: 'RO- Seating Area Issues', 102: 'RO- Sports Arena Activities', 103: 'RO- Staff Attitude', 104: 'RO- Traffic Issues', 105: 'Recall Cheque', 106: 'Receiving Old Cheques', 107: 'Rent', 108: 'Rental Data Update', 109: 'Request-schedule Inspection Inquiry', 110: 'Reset App Device', 111: 'Retail Operation', 112: 'Safety', 113: 'Sales Contract', 114: 'Security Hazard', 115: 'Shuttle Bus', 116: 'Signage', 117: 'Snag Completion Date Inquiry', 118: 'Sports courts reservation', 119: 'Staff Attitude', 120: 'Swimming Pool', 121: 'Technical', 122: 'Technical Request', 123: 'Theft Incident', 124: 'Traffic issues MSA', 125: 'Transfer', 126: 'Triple Play Services', 127: 'Utilities', 128: 'Utilities Consumption Dispute', 129: 'Violation', 130: 'Waste Collection', 131: 'Water cut', 132: 'WhatsApp number', 133: 'Work Permits'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to tokenize and encode text\n",
    "def encode_texts(texts, tokenizer, max_length=128):\n",
    "    return tokenizer(texts, padding=True, truncation=True, return_tensors='tf', max_length=max_length)\n",
    "\n",
    "# Function to generate BERT embeddings for a batch of input text\n",
    "def generate_bert_embeddings(texts, tokenizer=BertTokenizer.from_pretrained('bert-base-uncased'), bert_model=TFBertModel.from_pretrained('bert-base-uncased'), max_length=128):\n",
    "    # Tokenize and encode the text data\n",
    "    encoded_inputs = encode_texts(texts, tokenizer, max_length)\n",
    "    \n",
    "    # Run the BERT model on the tokenized text\n",
    "    outputs = bert_model(encoded_inputs['input_ids'], attention_mask=encoded_inputs['attention_mask'])\n",
    "    \n",
    "    # Get the pooled output (CLS token)\n",
    "    pooled_output = outputs.pooler_output.numpy()\n",
    "    \n",
    "    return pooled_output\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove Special shit \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  \n",
    "    # Remove extra whitespace\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def Process_Input(text):\n",
    "    text = clean_text(text)\n",
    "    Berts = generate_bert_embeddings(text,tokenizer,bert_model,max_length=128)\n",
    "    return Berts\n",
    "\n",
    "def IF_XGBOOST(text,model,label_mapping,XG_FLAG):\n",
    "    if XG_FLAG == 0 :\n",
    "        top2 = Make_prediction1(text, model, label_mapping)\n",
    "    else : \n",
    "        top2 = Make_prediction2(text, model, label_mapping)\n",
    "    return top2 \n",
    "\n",
    "def Make_prediction2(text, model, label_mapping):\n",
    "    Berts = Process_Input(text)\n",
    "    \n",
    "    # Ensure Berts is 2D\n",
    "    if len(Berts.shape) == 1:\n",
    "        Berts = Berts.reshape(1, -1)\n",
    "    \n",
    "    predictions = model.predict(Berts)\n",
    "    print(f\"Predictions: {predictions}\")  # Debug print\n",
    "    \n",
    "    # Ensure predictions are numeric\n",
    "    if isinstance(predictions, np.ndarray):\n",
    "        print(f\"Predictions type: {type(predictions)}, Shape: {predictions.shape}\")\n",
    "    else:\n",
    "        raise ValueError(\"Predictions are not of expected type: numpy array.\")\n",
    "    \n",
    "    # Handle 1D predictions (e.g., XGBoost)\n",
    "    if len(predictions.shape) == 1:\n",
    "        top_2_indices = np.argsort(predictions)[-2:][::-1]\n",
    "        top_2_categories = [(label_mapping[idx], predictions[idx]) for idx in top_2_indices]\n",
    "    else:\n",
    "        # Handle 2D predictions\n",
    "        top_2_indices = np.argsort(predictions, axis=1)[:, -2:][:, ::-1]\n",
    "        top_2_categories = [\n",
    "            [(label_mapping[idx], predictions[i, idx]) for idx in sample_top_2]\n",
    "            for i, sample_top_2 in enumerate(top_2_indices)\n",
    "        ]\n",
    "    \n",
    "    return top_2_categories\n",
    "\n",
    "\n",
    "\n",
    "def Make_prediction1(text, model, label_mapping):\n",
    "    # Process input text to get embeddings\n",
    "    Berts = Process_Input(text)\n",
    "    \n",
    "    # Simulate model predictions (Replace with `model.predict`)\n",
    "    predictions = model.predict(Berts)  # Example probabilities\n",
    "    # Get top 2 predictions\n",
    "    top_2_indices = np.argsort(predictions, axis=1)[:, -2:][:, ::-1]\n",
    "    top_2_categories = [\n",
    "        [(label_mapping[idx], predictions[0, idx]) for idx in sample_top_2]\n",
    "        for sample_top_2 in top_2_indices\n",
    "    ]\n",
    "    return top_2_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Load models\n",
    "Model_path_1 = r\"D:\\Comlaint Analysis Model\\Models that are 4o5a5\\LSTM_MODEL_ft.keras\"\n",
    "Model_path_2 = r\"D:\\Comlaint Analysis Model\\xgboost_model.joblib\"\n",
    "Model_path_3 = r\"D:\\Comlaint Analysis Model\\Models that are 4o5a5\\5ara LSTM.keras\"\n",
    "Loaded_Model1 = load_model(Model_path_1)\n",
    "Loaded_Model2 = joblib.load(Model_path_2)\n",
    "Loaded_Model3 = load_model(Model_path_3)\n",
    "XG_FLAG = 0\n",
    "# Default selected model\n",
    "Loaded_Model = Loaded_Model1  # Set an initial default model\n",
    "\n",
    "def change_model():\n",
    "    \"\"\"Update the Loaded_Model based on user selection.\"\"\"\n",
    "    global Loaded_Model\n",
    "    global XG_FLAG\n",
    "    selected_model = model_var.get()\n",
    "    if selected_model == 1:\n",
    "        Loaded_Model = Loaded_Model1\n",
    "        XG_FLAG = 0\n",
    "    elif selected_model == 2:\n",
    "        Loaded_Model = Loaded_Model2\n",
    "        XG_FLAG = 1\n",
    "    elif selected_model == 3:\n",
    "        Loaded_Model = Loaded_Model3\n",
    "        XG_FLAG = 0\n",
    "\n",
    "def categorize_input():\n",
    "    user_input = input_text.get(\"1.0\", tk.END).strip()  # Get input from text area\n",
    "    if not user_input:\n",
    "        messagebox.showerror(\"Error\", \"Please enter a valid input.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Call Make_prediction\n",
    "        top_2_predictions = IF_XGBOOST(user_input, Loaded_Model, label_mapping,XG_FLAG)\n",
    "        \n",
    "        # Format the results\n",
    "        formatted_result = \"\\n\".join(\n",
    "            [f\"{category}: {prob:.2%}\" for category, prob in top_2_predictions[0]]\n",
    "        )\n",
    "        \n",
    "        # Update the result label\n",
    "        result_label.config(text=f\"Predicted Categories:\\n{formatted_result}\", fg=\"green\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred: {str(e)}\")\n",
    "\n",
    "# Initialize main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Complaint Categorization\")\n",
    "root.geometry(\"500x400\")\n",
    "\n",
    "# UI Components\n",
    "title_label = tk.Label(root, text=\"Complaint Categorization\", font=(\"Arial\", 16, \"bold\"))\n",
    "title_label.pack(pady=10)\n",
    "\n",
    "instructions_label = tk.Label(root, text=\"Enter your complaint or text below:\")\n",
    "instructions_label.pack()\n",
    "\n",
    "input_text = tk.Text(root, height=8, width=50)\n",
    "input_text.pack(pady=5)\n",
    "\n",
    "# Model selection checkboxes\n",
    "model_var = tk.IntVar(value=1)  # Default model is the first one\n",
    "\n",
    "checkbox1 = tk.Radiobutton(root, text=\"Use LSTM Model 1\", variable=model_var, value=1, command=change_model)\n",
    "checkbox1.pack()\n",
    "\n",
    "checkbox3 = tk.Radiobutton(root, text=\"Use LSTM Model 2\", variable=model_var, value=3, command=change_model)\n",
    "checkbox3.pack()\n",
    "\n",
    "categorize_button = tk.Button(root, text=\"Categorize\", command=categorize_input, bg=\"blue\", fg=\"white\")\n",
    "categorize_button.pack(pady=10)\n",
    "\n",
    "result_label = tk.Label(root, text=\"\", font=(\"Helvetica\", 12))\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.4.1-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from ollama) (0.27.0)\n",
      "Collecting pydantic<3.0.0,>=2.9.0 (from ollama)\n",
      "  Downloading pydantic-2.10.1-py3-none-any.whl.metadata (169 kB)\n",
      "     ---------------------------------------- 0.0/169.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/169.7 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/169.7 kB ? eta -:--:--\n",
      "     -------- ---------------------------- 41.0/169.7 kB 487.6 kB/s eta 0:00:01\n",
      "     -------- ---------------------------- 41.0/169.7 kB 487.6 kB/s eta 0:00:01\n",
      "     -------- ---------------------------- 41.0/169.7 kB 487.6 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 133.1/169.7 kB 525.1 kB/s eta 0:00:01\n",
      "     ------------------------------------ 169.7/169.7 kB 681.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: anyio in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.6.0)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Downloading pydantic_core-2.27.1-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading ollama-0.4.1-py3-none-any.whl (12 kB)\n",
      "Downloading pydantic-2.10.1-py3-none-any.whl (455 kB)\n",
      "   ---------------------------------------- 0.0/455.3 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/455.3 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/455.3 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 71.7/455.3 kB 563.7 kB/s eta 0:00:01\n",
      "   ---------- --------------------------- 122.9/455.3 kB 798.9 kB/s eta 0:00:01\n",
      "   ----------- -------------------------- 143.4/455.3 kB 774.0 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 153.6/455.3 kB 654.6 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 194.6/455.3 kB 655.9 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 204.8/455.3 kB 593.2 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 225.3/455.3 kB 550.0 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 235.5/455.3 kB 533.8 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 256.0/455.3 kB 507.8 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 256.0/455.3 kB 507.8 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 286.7/455.3 kB 491.1 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 286.7/455.3 kB 491.1 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 307.2/455.3 kB 463.3 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 307.2/455.3 kB 463.3 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 317.4/455.3 kB 418.5 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 317.4/455.3 kB 418.5 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 337.9/455.3 kB 388.2 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 337.9/455.3 kB 388.2 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 358.4/455.3 kB 371.2 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 358.4/455.3 kB 371.2 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 368.6/455.3 kB 342.3 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 368.6/455.3 kB 342.3 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 368.6/455.3 kB 342.3 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 389.1/455.3 kB 327.8 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 399.4/455.3 kB 315.3 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 399.4/455.3 kB 315.3 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 419.8/455.3 kB 312.0 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 419.8/455.3 kB 312.0 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 440.3/455.3 kB 309.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 440.3/455.3 kB 309.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 455.3/455.3 kB 296.7 kB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.27.1-cp312-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.0 MB 131.3 kB/s eta 0:00:15\n",
      "    --------------------------------------- 0.0/2.0 MB 131.3 kB/s eta 0:00:15\n",
      "    --------------------------------------- 0.0/2.0 MB 131.3 kB/s eta 0:00:15\n",
      "    --------------------------------------- 0.0/2.0 MB 131.3 kB/s eta 0:00:15\n",
      "    --------------------------------------- 0.0/2.0 MB 131.3 kB/s eta 0:00:15\n",
      "    --------------------------------------- 0.0/2.0 MB 131.3 kB/s eta 0:00:15\n",
      "    --------------------------------------- 0.0/2.0 MB 70.3 kB/s eta 0:00:28\n",
      "    --------------------------------------- 0.0/2.0 MB 70.3 kB/s eta 0:00:28\n",
      "    --------------------------------------- 0.0/2.0 MB 70.3 kB/s eta 0:00:28\n",
      "    --------------------------------------- 0.0/2.0 MB 70.3 kB/s eta 0:00:28\n",
      "   - -------------------------------------- 0.1/2.0 MB 84.1 kB/s eta 0:00:23\n",
      "   - -------------------------------------- 0.1/2.0 MB 84.1 kB/s eta 0:00:23\n",
      "   - -------------------------------------- 0.1/2.0 MB 84.1 kB/s eta 0:00:23\n",
      "   - -------------------------------------- 0.1/2.0 MB 84.1 kB/s eta 0:00:23\n",
      "   - -------------------------------------- 0.1/2.0 MB 84.1 kB/s eta 0:00:23\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 71.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.1/2.0 MB 54.1 kB/s eta 0:00:36\n",
      "   -- ------------------------------------- 0.1/2.0 MB 37.3 kB/s eta 0:00:51\n",
      "   -- ------------------------------------- 0.1/2.0 MB 37.3 kB/s eta 0:00:51\n",
      "   -- ------------------------------------- 0.1/2.0 MB 37.3 kB/s eta 0:00:51\n",
      "   -- ------------------------------------- 0.1/2.0 MB 37.3 kB/s eta 0:00:51\n",
      "   -- ------------------------------------- 0.1/2.0 MB 37.3 kB/s eta 0:00:51\n",
      "   -- ------------------------------------- 0.1/2.0 MB 42.2 kB/s eta 0:00:45\n",
      "   -- ------------------------------------- 0.1/2.0 MB 42.2 kB/s eta 0:00:45\n",
      "   -- ------------------------------------- 0.1/2.0 MB 42.2 kB/s eta 0:00:45\n",
      "   -- ------------------------------------- 0.1/2.0 MB 42.2 kB/s eta 0:00:45\n",
      "   -- ------------------------------------- 0.1/2.0 MB 42.2 kB/s eta 0:00:45\n",
      "   -- ------------------------------------- 0.1/2.0 MB 42.2 kB/s eta 0:00:45\n",
      "   -- ------------------------------------- 0.1/2.0 MB 45.1 kB/s eta 0:00:41\n",
      "   -- ------------------------------------- 0.1/2.0 MB 45.1 kB/s eta 0:00:41\n",
      "   -- ------------------------------------- 0.1/2.0 MB 45.1 kB/s eta 0:00:41\n",
      "   -- ------------------------------------- 0.1/2.0 MB 45.1 kB/s eta 0:00:41\n",
      "   -- ------------------------------------- 0.1/2.0 MB 45.1 kB/s eta 0:00:41\n",
      "   -- ------------------------------------- 0.1/2.0 MB 45.1 kB/s eta 0:00:41\n",
      "   --- ------------------------------------ 0.2/2.0 MB 44.3 kB/s eta 0:00:42\n",
      "   --- ------------------------------------ 0.2/2.0 MB 44.3 kB/s eta 0:00:42\n",
      "   --- ------------------------------------ 0.2/2.0 MB 44.3 kB/s eta 0:00:42\n",
      "   --- ------------------------------------ 0.2/2.0 MB 48.5 kB/s eta 0:00:38\n",
      "   --- ------------------------------------ 0.2/2.0 MB 48.5 kB/s eta 0:00:38\n",
      "   --- ------------------------------------ 0.2/2.0 MB 50.0 kB/s eta 0:00:37\n",
      "   --- ------------------------------------ 0.2/2.0 MB 50.0 kB/s eta 0:00:37\n",
      "   --- ------------------------------------ 0.2/2.0 MB 50.0 kB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 53.7 kB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 53.7 kB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 53.7 kB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 56.9 kB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 56.9 kB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 58.1 kB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 58.1 kB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 58.1 kB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 61.2 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 61.2 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 61.2 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 61.2 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 61.2 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 61.2 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 61.2 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 61.2 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 61.2 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 61.2 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 61.2 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 61.2 kB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 56.3 kB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 56.3 kB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 56.3 kB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 56.3 kB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 56.3 kB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 57.5 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 57.5 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 57.5 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 57.5 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 57.5 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 57.5 kB/s eta 0:00:30\n",
      "   ------ --------------------------------- 0.3/2.0 MB 58.3 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 0.3/2.0 MB 58.3 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 0.3/2.0 MB 58.3 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 0.3/2.0 MB 58.3 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 0.3/2.0 MB 58.3 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 0.3/2.0 MB 58.3 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 0.3/2.0 MB 58.3 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 0.3/2.0 MB 58.3 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 0.3/2.0 MB 58.3 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 0.3/2.0 MB 58.3 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 0.3/2.0 MB 58.3 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 0.3/2.0 MB 58.3 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 0.3/2.0 MB 58.3 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 0.3/2.0 MB 54.2 kB/s eta 0:00:31\n",
      "   ------ --------------------------------- 0.3/2.0 MB 54.2 kB/s eta 0:00:31\n",
      "   ------ --------------------------------- 0.3/2.0 MB 54.2 kB/s eta 0:00:31\n",
      "   ------ --------------------------------- 0.3/2.0 MB 54.2 kB/s eta 0:00:31\n",
      "   ------ --------------------------------- 0.3/2.0 MB 54.2 kB/s eta 0:00:31\n",
      "   ------ --------------------------------- 0.3/2.0 MB 54.2 kB/s eta 0:00:31\n",
      "   ------ --------------------------------- 0.3/2.0 MB 54.2 kB/s eta 0:00:31\n",
      "   ------ --------------------------------- 0.3/2.0 MB 54.2 kB/s eta 0:00:31\n",
      "   ------ --------------------------------- 0.3/2.0 MB 54.2 kB/s eta 0:00:31\n",
      "   ------ --------------------------------- 0.3/2.0 MB 54.2 kB/s eta 0:00:31\n",
      "   ------ --------------------------------- 0.3/2.0 MB 54.2 kB/s eta 0:00:31\n",
      "   ------ --------------------------------- 0.3/2.0 MB 54.2 kB/s eta 0:00:31\n",
      "   ------ --------------------------------- 0.3/2.0 MB 54.2 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.3/2.0 MB 53.7 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.3/2.0 MB 53.7 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.3/2.0 MB 53.7 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.3/2.0 MB 53.7 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.3/2.0 MB 53.7 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.4/2.0 MB 54.8 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 0.4/2.0 MB 54.8 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 0.4/2.0 MB 54.8 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 0.4/2.0 MB 54.8 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 0.4/2.0 MB 54.8 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 0.4/2.0 MB 54.8 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 0.4/2.0 MB 54.8 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 0.4/2.0 MB 54.8 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 0.4/2.0 MB 54.8 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 0.4/2.0 MB 54.8 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 0.4/2.0 MB 54.8 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 0.4/2.0 MB 54.8 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 0.4/2.0 MB 54.8 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 0.4/2.0 MB 53.1 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.4/2.0 MB 53.1 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.4/2.0 MB 53.1 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.4/2.0 MB 53.1 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.4/2.0 MB 53.1 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.4/2.0 MB 53.1 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.4/2.0 MB 53.1 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.4/2.0 MB 53.1 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.4/2.0 MB 53.1 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.4/2.0 MB 53.1 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.4/2.0 MB 53.1 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.4/2.0 MB 53.1 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.4/2.0 MB 53.1 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 0.4/2.0 MB 53.1 kB/s eta 0:00:31\n",
      "   -------- ------------------------------- 0.4/2.0 MB 49.9 kB/s eta 0:00:32\n",
      "   -------- ------------------------------- 0.4/2.0 MB 49.9 kB/s eta 0:00:32\n",
      "   -------- ------------------------------- 0.4/2.0 MB 49.9 kB/s eta 0:00:32\n",
      "   -------- ------------------------------- 0.4/2.0 MB 49.9 kB/s eta 0:00:32\n",
      "   -------- ------------------------------- 0.4/2.0 MB 51.4 kB/s eta 0:00:31\n",
      "   -------- ------------------------------- 0.4/2.0 MB 51.4 kB/s eta 0:00:31\n",
      "   -------- ------------------------------- 0.4/2.0 MB 51.4 kB/s eta 0:00:31\n",
      "   -------- ------------------------------- 0.4/2.0 MB 51.4 kB/s eta 0:00:31\n",
      "   -------- ------------------------------- 0.4/2.0 MB 51.4 kB/s eta 0:00:31\n",
      "   -------- ------------------------------- 0.4/2.0 MB 51.4 kB/s eta 0:00:31\n",
      "   -------- ------------------------------- 0.4/2.0 MB 50.9 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 0.5/2.0 MB 53.1 kB/s eta 0:00:29\n",
      "   --------- ------------------------------ 0.5/2.0 MB 53.1 kB/s eta 0:00:29\n",
      "   --------- ------------------------------ 0.5/2.0 MB 53.1 kB/s eta 0:00:29\n",
      "   --------- ------------------------------ 0.5/2.0 MB 53.1 kB/s eta 0:00:29\n",
      "   --------- ------------------------------ 0.5/2.0 MB 54.4 kB/s eta 0:00:28\n",
      "   --------- ------------------------------ 0.5/2.0 MB 54.4 kB/s eta 0:00:28\n",
      "   --------- ------------------------------ 0.5/2.0 MB 54.8 kB/s eta 0:00:28\n",
      "   --------- ------------------------------ 0.5/2.0 MB 54.8 kB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 56.6 kB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 56.6 kB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 57.1 kB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 57.1 kB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 57.1 kB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 57.1 kB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 58.5 kB/s eta 0:00:25\n",
      "   ----------- ---------------------------- 0.6/2.0 MB 60.4 kB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 0.6/2.0 MB 60.4 kB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 0.6/2.0 MB 60.9 kB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 0.6/2.0 MB 60.9 kB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 0.6/2.0 MB 62.5 kB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 0.6/2.0 MB 62.5 kB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 0.6/2.0 MB 63.0 kB/s eta 0:00:23\n",
      "   ------------ --------------------------- 0.6/2.0 MB 64.7 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 0.6/2.0 MB 64.7 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 0.6/2.0 MB 66.3 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 0.6/2.0 MB 66.3 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 0.6/2.0 MB 66.8 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 0.7/2.0 MB 68.5 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 0.7/2.0 MB 69.3 kB/s eta 0:00:19\n",
      "   -------------- ------------------------- 0.7/2.0 MB 70.9 kB/s eta 0:00:19\n",
      "   -------------- ------------------------- 0.7/2.0 MB 72.7 kB/s eta 0:00:18\n",
      "   -------------- ------------------------- 0.7/2.0 MB 72.7 kB/s eta 0:00:18\n",
      "   -------------- ------------------------- 0.7/2.0 MB 73.3 kB/s eta 0:00:18\n",
      "   --------------- ------------------------ 0.7/2.0 MB 75.0 kB/s eta 0:00:17\n",
      "   --------------- ------------------------ 0.8/2.0 MB 75.7 kB/s eta 0:00:17\n",
      "   --------------- ------------------------ 0.8/2.0 MB 77.3 kB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 79.1 kB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 79.8 kB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 81.5 kB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 0.9/2.0 MB 83.8 kB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 0.9/2.0 MB 85.6 kB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 0.9/2.0 MB 86.3 kB/s eta 0:00:13\n",
      "   ------------------ --------------------- 0.9/2.0 MB 88.6 kB/s eta 0:00:13\n",
      "   ------------------ --------------------- 0.9/2.0 MB 90.4 kB/s eta 0:00:12\n",
      "   ------------------ --------------------- 0.9/2.0 MB 90.4 kB/s eta 0:00:12\n",
      "   ------------------- -------------------- 1.0/2.0 MB 92.4 kB/s eta 0:00:11\n",
      "   ------------------- -------------------- 1.0/2.0 MB 94.2 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 1.0/2.0 MB 94.9 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 1.0/2.0 MB 96.3 kB/s eta 0:00:11\n",
      "   --------------------- ------------------ 1.0/2.0 MB 97.8 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 1.1/2.0 MB 99.3 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 1.1/2.0 MB 99.3 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 1.1/2.0 MB 99.3 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 1.1/2.0 MB 99.3 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 1.1/2.0 MB 99.3 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 1.1/2.0 MB 99.3 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 1.1/2.0 MB 97.6 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 1.1/2.0 MB 97.6 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 1.1/2.0 MB 97.6 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 1.1/2.0 MB 97.6 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.6 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.6 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.7 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.7 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.7 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.7 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.7 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.7 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.7 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.7 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.7 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.7 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.7 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.7 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 97.7 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 94.5 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 94.5 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 94.5 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 94.5 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 94.5 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 94.5 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 94.5 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 1.1/2.0 MB 93.9 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.1/2.0 MB 93.9 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.1/2.0 MB 93.9 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.1/2.0 MB 93.9 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.1/2.0 MB 93.9 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.2/2.0 MB 92.4 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.2/2.0 MB 92.4 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.2/2.0 MB 92.4 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.2/2.0 MB 92.4 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.2/2.0 MB 91.8 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.2/2.0 MB 91.8 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.2/2.0 MB 91.8 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 92.4 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 92.4 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 92.4 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 93.1 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 93.1 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 93.1 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 1.2/2.0 MB 92.7 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 91.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 1.3/2.0 MB 86.5 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 1.3/2.0 MB 86.5 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 1.3/2.0 MB 86.5 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 1.3/2.0 MB 86.5 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 1.3/2.0 MB 87.0 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 1.3/2.0 MB 87.0 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 1.3/2.0 MB 87.0 kB/s eta 0:00:09\n",
      "   -------------------------- ------------- 1.3/2.0 MB 87.6 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 1.3/2.0 MB 87.6 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 1.3/2.0 MB 87.7 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 1.3/2.0 MB 87.7 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 1.3/2.0 MB 88.4 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 1.3/2.0 MB 88.4 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 1.3/2.0 MB 88.4 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 1.4/2.0 MB 88.2 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 1.4/2.0 MB 88.2 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 1.4/2.0 MB 88.2 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 1.4/2.0 MB 88.8 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 1.4/2.0 MB 88.8 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 89.6 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 89.6 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 89.6 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 89.7 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 89.7 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 89.7 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 89.7 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 89.7 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 89.7 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 89.7 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 89.0 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 89.0 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 89.0 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 88.9 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 88.9 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 88.9 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 88.9 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 88.9 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 88.9 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.6 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.6 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.6 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.6 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.6 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.7 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.7 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.7 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.7 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.7 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.7 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.7 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.7 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.7 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.7 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 88.7 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 86.4 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 86.4 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 86.4 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 86.4 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 86.4 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 1.5/2.0 MB 86.4 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 1.5/2.0 MB 86.4 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 1.5/2.0 MB 86.4 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 1.5/2.0 MB 86.4 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 1.5/2.0 MB 86.4 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 1.5/2.0 MB 86.4 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 1.5/2.0 MB 86.4 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 1.5/2.0 MB 86.4 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 1.5/2.0 MB 86.4 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 1.5/2.0 MB 86.3 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 1.5/2.0 MB 86.3 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 1.6/2.0 MB 87.0 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 1.6/2.0 MB 87.0 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 1.6/2.0 MB 86.9 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 1.6/2.0 MB 86.9 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 1.6/2.0 MB 87.6 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 1.6/2.0 MB 87.6 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 1.6/2.0 MB 87.6 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 1.6/2.0 MB 87.6 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 1.6/2.0 MB 87.6 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 1.6/2.0 MB 87.6 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 1.6/2.0 MB 87.6 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 86.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 86.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 86.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 86.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 86.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 86.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 86.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 86.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 86.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 85.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 85.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 85.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 85.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 85.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 85.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 85.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 85.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 85.7 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 1.6/2.0 MB 85.7 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 1.6/2.0 MB 85.4 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 1.6/2.0 MB 85.4 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 1.7/2.0 MB 86.0 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 1.7/2.0 MB 86.0 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 1.7/2.0 MB 86.0 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 1.7/2.0 MB 85.9 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 1.7/2.0 MB 85.9 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 1.7/2.0 MB 86.5 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 1.7/2.0 MB 86.5 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 1.7/2.0 MB 87.1 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 1.7/2.0 MB 87.1 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 1.7/2.0 MB 87.4 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 88.1 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 88.1 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 88.2 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 89.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 83.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 83.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 83.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 83.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 83.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 83.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 83.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 83.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 83.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 83.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 83.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 83.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 81.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 81.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 81.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 81.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 81.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 81.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 81.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 81.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 1.8/2.0 MB 81.0 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 1.8/2.0 MB 81.0 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 1.8/2.0 MB 81.0 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 1.8/2.0 MB 80.8 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 1.8/2.0 MB 80.8 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 1.8/2.0 MB 80.8 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 1.9/2.0 MB 81.3 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 1.9/2.0 MB 81.3 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 1.9/2.0 MB 81.8 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 1.9/2.0 MB 81.8 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 1.9/2.0 MB 81.9 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 1.9/2.0 MB 81.9 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 1.9/2.0 MB 82.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.9/2.0 MB 82.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.9/2.0 MB 82.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/2.0 MB 83.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/2.0 MB 83.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 84.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 84.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 84.5 kB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, pydantic-core, pydantic, ollama\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.6\n",
      "    Uninstalling pydantic_core-2.14.6:\n",
      "      Successfully uninstalled pydantic_core-2.14.6\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.3\n",
      "    Uninstalling pydantic-2.5.3:\n",
      "      Successfully uninstalled pydantic-2.5.3\n",
      "Successfully installed ollama-0.4.1 pydantic-2.10.1 pydantic-core-2.27.1 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"D:\\Balanced_DS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google.generativeai\n",
      "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.10 (from google.generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google.generativeai)\n",
      "  Downloading google_api_core-2.23.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google.generativeai)\n",
      "  Downloading google_api_python_client-2.154.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google.generativeai)\n",
      "  Downloading google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from google.generativeai) (3.20.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from google.generativeai) (2.10.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from google.generativeai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from google.generativeai) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.10->google.generativeai)\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google.generativeai)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core->google.generativeai) (2.32.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google.generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google.generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google.generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic->google.generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic->google.generativeai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->google.generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google.generativeai) (1.67.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google.generativeai)\n",
      "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google.generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ykhalifa\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2024.8.30)\n",
      "Collecting protobuf (from google.generativeai)\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google.generativeai)\n",
      "  Downloading grpcio-1.68.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Downloading google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.8 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 30.7/160.8 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 112.6/160.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 160.8/160.8 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
      "   ---------------------------------------- 0.0/760.0 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 184.3/760.0 kB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 430.1/760.0 kB 6.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 665.6/760.0 kB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 760.0/760.0 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.23.0-py3-none-any.whl (156 kB)\n",
      "   ---------------------------------------- 0.0/156.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 156.6/156.6 kB 9.1 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "   ---------------------------------------- 0.0/209.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 209.5/209.5 kB 12.5 MB/s eta 0:00:00\n",
      "Downloading google_api_python_client-2.154.0-py2.py3-none-any.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/12.6 MB 13.1 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.8/12.6 MB 9.7 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.2/12.6 MB 9.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.7/12.6 MB 9.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.0/12.6 MB 9.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.5/12.6 MB 9.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.9/12.6 MB 9.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.3/12.6 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.8/12.6 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.0/12.6 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.1/12.6 MB 8.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.4/12.6 MB 8.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.9/12.6 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.3/12.6 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.8/12.6 MB 8.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.3/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.7/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.5/12.6 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.9/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.3/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.8/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.0/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.1/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.9/12.6 MB 8.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.3/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 8.5 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "   ---------------------------------------- 0.0/221.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 221.7/221.7 kB 6.8 MB/s eta 0:00:00\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB 2.7 MB/s eta 0:00:00\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio_status-1.68.0-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.5 kB ? eta -:--:--\n",
      "   ------------------------ -------------- 276.5/431.5 kB 16.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 431.5/431.5 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.68.0-cp312-cp312-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.4/4.4 MB 8.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.8/4.4 MB 8.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.0/4.4 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.5/4.4 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.0/4.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.5/4.4 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.8/4.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.3/4.4 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.6/4.4 MB 8.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.9/4.4 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.0/4.4 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.2/4.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 7.6 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, rsa, protobuf, httplib2, grpcio, proto-plus, googleapis-common-protos, google-auth, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google.generativeai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.67.0\n",
      "    Uninstalling grpcio-1.67.0:\n",
      "      Successfully uninstalled grpcio-1.67.0\n",
      "Successfully installed google-ai-generativelanguage-0.6.10 google-api-core-2.23.0 google-api-python-client-2.154.0 google-auth-2.36.0 google-auth-httplib2-0.2.0 google.generativeai-0.8.3 googleapis-common-protos-1.66.0 grpcio-1.68.0 grpcio-status-1.68.0 httplib2-0.22.0 proto-plus-1.25.0 protobuf-5.28.3 rsa-4.9 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.32.0 requires protobuf<5,>=3.20, but you have protobuf 5.28.3 which is incompatible.\n",
      "tensorflow-intel 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get(\"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\")\n",
    "url = \"https://api.groq.com/openai/v1/models\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_To_generate = pd.read_csv(\"invalid_Classes.csv\",header = None)\n",
    "data_ = pd.read_csv(r\"D:\\train Scripts\\Limited_Table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes_To_generate = data_['PROBLEM_CODE'].unique().tolist()\n",
    "#classes_To_generate.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyDAc56LBVDDYHnO0E6h__SbjmZzjlCwbT0\")\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data to Be Generated : 1\n",
      "Finished Class: Reset App Device\n",
      "Data to Be Generated : 2\n",
      "Finished Class: Access Control\n",
      "Data to Be Generated : 12\n",
      "Finished Class: Elevators\n",
      "Data to Be Generated : 12\n",
      "Finished Class: Expected Handover Date\n",
      "Data to Be Generated : 16\n",
      "Finished Class: RO- General Inquires / Suggestions\n",
      "Data to Be Generated : 18\n",
      "Finished Class: Maintenance Difference\n",
      "Data to Be Generated : 22\n",
      "Finished Class: Snag Completion Date Inquiry\n",
      "Data to Be Generated : 23\n",
      "Finished Class: Transfer\n",
      "Data to Be Generated : 27\n",
      "Finished Class: RO- Beach Access complains\n",
      "Data to Be Generated : 30\n",
      "Finished Class: Finance\n",
      "Data to Be Generated : 31\n",
      "Finished Class: Meters\n",
      "Data to Be Generated : 34\n",
      "Finished Class: RO- Parking Issues\n",
      "Data to Be Generated : 41\n",
      "Finished Class: Carpentry\n",
      "Data to Be Generated : 45\n",
      "Warning: Model returned only 44 samples for Class General Queries.\n",
      "Finished Class: General Queries\n",
      "Data to Be Generated : 50\n",
      "Warning: Model returned only 49 samples for Class Swimming Pool.\n",
      "Finished Class: Swimming Pool\n",
      "Data to Be Generated : 63\n",
      "Warning: Model returned only 55 samples for Class Plumbing-DLP.\n",
      "Finished Class: Plumbing-DLP\n",
      "Data to Be Generated : 69\n",
      "Warning: Model returned only 58 samples for Class Technical Request.\n",
      "Finished Class: Technical Request\n",
      "Data to Be Generated : 75\n",
      "Warning: Model returned only 60 samples for Class Dues Inquiries.\n",
      "Finished Class: Dues Inquiries\n",
      "Data to Be Generated : 75\n",
      "Warning: Model returned only 71 samples for Class Aluminum.\n",
      "Finished Class: Aluminum\n",
      "Data to Be Generated : 79\n",
      "Warning: Model returned only 71 samples for Class RO- Cleaning issues.\n",
      "Finished Class: RO- Cleaning issues\n",
      "Data to Be Generated : 81\n",
      "Finished Class: Handover Letter Acknowledgment by Customer\n",
      "Data to Be Generated : 92\n",
      "Warning: Model returned only 76 samples for Class RO- Gym- Qulaity of Equipment.\n",
      "Finished Class: RO- Gym- Qulaity of Equipment\n",
      "Data to Be Generated : 92\n",
      "Warning: Model returned only 88 samples for Class RO- Sports Arena Activities.\n",
      "Finished Class: RO- Sports Arena Activities\n",
      "Data to Be Generated : 93\n",
      "Warning: Model returned only 73 samples for Class CM Office.\n",
      "Finished Class: CM Office\n",
      "Data to Be Generated : 93\n",
      "Warning: Model returned only 70 samples for Class RO- Rules Violation.\n",
      "Finished Class: RO- Rules Violation\n",
      "Data to Be Generated : 94\n",
      "Warning: Model returned only 83 samples for Class Mosque.\n",
      "Finished Class: Mosque\n",
      "Data to Be Generated : 99\n",
      "Warning: Model returned only 92 samples for Class Access Permission.\n",
      "Finished Class: Access Permission\n",
      "Data to Be Generated : 105\n",
      "Warning: Model returned only 68 samples for Class Carpentry-DLP.\n",
      "Finished Class: Carpentry-DLP\n",
      "Data to Be Generated : 109\n",
      "Warning: Model returned only 77 samples for Class AC_DLP.\n",
      "Finished Class: AC_DLP\n",
      "Data to Be Generated : 113\n",
      "Finished Class: Collection Complaint\n",
      "Data to Be Generated : 114\n",
      "Warning: Model returned only 83 samples for Class Fiber Cable.\n",
      "Finished Class: Fiber Cable\n",
      "Data to Be Generated : 116\n",
      "Warning: Model returned only 97 samples for Class Irrigation.\n",
      "Finished Class: Irrigation\n",
      "Data to Be Generated : 120\n",
      "Warning: Model returned only 108 samples for Class RO- Maintenance.\n",
      "Finished Class: RO- Maintenance\n",
      "Data to Be Generated : 125\n",
      "Warning: Model returned only 95 samples for Class Early Handover Request.\n",
      "Finished Class: Early Handover Request\n",
      "Data to Be Generated : 130\n",
      "Finished Class: Violation\n",
      "Data to Be Generated : 137\n",
      "Finished Class: Aluminum_DLP\n",
      "Data to Be Generated : 137\n",
      "Warning: Model returned only 99 samples for Class Electrical-DLP.\n",
      "Finished Class: Electrical-DLP\n",
      "Data to Be Generated : 140\n",
      "Warning: Model returned only 91 samples for Class Delivery Cheque Collection Inquiry.\n",
      "Finished Class: Delivery Cheque Collection Inquiry\n",
      "Data to Be Generated : 143\n",
      "Warning: Model returned only 91 samples for Class RO- Lack of Safety precautions.\n",
      "Finished Class: RO- Lack of Safety precautions\n",
      "Data to Be Generated : 143\n",
      "Warning: Model returned only 131 samples for Class Water cut.\n",
      "Finished Class: Water cut\n",
      "Data to Be Generated : 144\n",
      "Warning: Model returned only 86 samples for Class Data Violation.\n",
      "Finished Class: Data Violation\n",
      "Data to Be Generated : 146\n",
      "Warning: Model returned only 101 samples for Class Lost and Found.\n",
      "Finished Class: Lost and Found\n",
      "Data to Be Generated : 147\n",
      "Warning: Model returned only 99 samples for Class RO- Noise - Operation Staff.\n",
      "Finished Class: RO- Noise - Operation Staff\n",
      "Data to Be Generated : 149\n",
      "Warning: Model returned only 89 samples for Class RO- Noise - Private workers.\n",
      "Finished Class: RO- Noise - Private workers\n",
      "Data to Be Generated : 150\n",
      "Warning: Model returned only 94 samples for Class RO- Seating Area Issues.\n",
      "Finished Class: RO- Seating Area Issues\n",
      "Data to Be Generated : 150\n",
      "Warning: Model returned only 148 samples for Class Design Dispute.\n",
      "Finished Class: Design Dispute\n",
      "Data to Be Generated : 153\n",
      "Warning: Model returned only 96 samples for Class Technical.\n",
      "Finished Class: Technical\n",
      "Data to Be Generated : 153\n",
      "Warning: Model returned only 107 samples for Class Request-schedule Inspection Inquiry.\n",
      "Finished Class: Request-schedule Inspection Inquiry\n",
      "Data to Be Generated : 156\n",
      "Warning: Model returned only 104 samples for Class Community Center.\n",
      "Finished Class: Community Center\n",
      "Data to Be Generated : 156\n",
      "Warning: Model returned only 105 samples for Class Gas Cylinder.\n",
      "Finished Class: Gas Cylinder\n",
      "Data to Be Generated : 157\n",
      "Warning: Model returned only 121 samples for Class RO- Traffic Issues.\n",
      "Finished Class: RO- Traffic Issues\n",
      "Data to Be Generated : 161\n",
      "Finished Class: Physical Fights\n",
      "Data to Be Generated : 161\n",
      "Warning: Model returned only 118 samples for Class Call Center internal escalation.\n",
      "Finished Class: Call Center internal escalation\n",
      "Data to Be Generated : 164\n",
      "Warning: Model returned only 117 samples for Class Access Permission - MSA.\n",
      "Finished Class: Access Permission - MSA\n",
      "Data to Be Generated : 164\n",
      "Warning: Model returned only 85 samples for Class Traffic issues MSA.\n",
      "Finished Class: Traffic issues MSA\n",
      "Data to Be Generated : 165\n",
      "Warning: Model returned only 119 samples for Class RO- Food And Beverage Quailty issues.\n",
      "Finished Class: RO- Food And Beverage Quailty issues\n",
      "Data to Be Generated : 166\n",
      "Warning: Model returned only 129 samples for Class Projects facilities working hours.\n",
      "Finished Class: Projects facilities working hours\n",
      "Data to Be Generated : 167\n",
      "Warning: Model returned only 115 samples for Class Follow Up on Email.\n",
      "Finished Class: Follow Up on Email\n",
      "Data to Be Generated : 167\n",
      "Warning: Model returned only 104 samples for Class Delay Penalty.\n",
      "Finished Class: Delay Penalty\n",
      "Data to Be Generated : 167\n",
      "Warning: Model returned only 117 samples for Class Check Collection.\n",
      "Finished Class: Check Collection\n",
      "Data to Be Generated : 168\n",
      "Warning: Model returned only 111 samples for Class Floor Plan Request- As built / Paint code.\n",
      "Finished Class: Floor Plan Request- As built / Paint code\n",
      "Data to Be Generated : 169\n",
      "Warning: Model returned only 126 samples for Class Insurance Amount Refund.\n",
      "Finished Class: Insurance Amount Refund\n",
      "Data to Be Generated : 169\n",
      "Warning: Model returned only 123 samples for Class RO- Gym- Lack of Equipment.\n",
      "Finished Class: RO- Gym- Lack of Equipment\n",
      "Data to Be Generated : 170\n",
      "Finished Class: RO- Clubhouse Room Reservations\n",
      "Data to Be Generated : 170\n",
      "Warning: Model returned only 112 samples for Class Business proposal.\n",
      "Finished Class: Business proposal\n",
      "Data to Be Generated : 170\n",
      "Warning: Model returned only 149 samples for Class Rental Data Update.\n",
      "Finished Class: Rental Data Update\n",
      "Data to Be Generated : 170\n",
      "Warning: Model returned only 127 samples for Class RO- Events Issues.\n",
      "Finished Class: RO- Events Issues\n",
      "Data to Be Generated : 171\n",
      "Finished Class: Customer Data update\n",
      "Data to Be Generated : 171\n",
      "Warning: Model returned only 115 samples for Class Work Permits.\n",
      "Finished Class: Work Permits\n",
      "Data to Be Generated : 172\n",
      "Warning: Model returned only 165 samples for Class Safety.\n",
      "Finished Class: Safety\n",
      "Data to Be Generated : 173\n",
      "Warning: Model returned only 112 samples for Class RO- Kids Area - Lack of Equipment/ Activities.\n",
      "Finished Class: RO- Kids Area - Lack of Equipment/ Activities\n",
      "Data to Be Generated : 174\n",
      "Warning: Model returned only 81 samples for Class RO- Events Parking Issues.\n",
      "Finished Class: RO- Events Parking Issues\n",
      "Data to Be Generated : 175\n",
      "Finished Class: RO- Access Premission\n",
      "Data to Be Generated : 175\n",
      "Warning: Model returned only 122 samples for Class Blacksmith.\n",
      "Finished Class: Blacksmith\n",
      "Data to Be Generated : 177\n",
      "Warning: Model returned only 97 samples for Class RO- Operating Premission.\n",
      "Finished Class: RO- Operating Premission\n",
      "Data to Be Generated : 179\n",
      "Warning: Model returned only 124 samples for Class Emaar Misr application Technical Issue.\n",
      "Finished Class: Emaar Misr application Technical Issue\n",
      "Data to Be Generated : 179\n",
      "Warning: Model returned only 155 samples for Class Sales Contract.\n",
      "Finished Class: Sales Contract\n",
      "Data to Be Generated : 181\n",
      "Warning: Model returned only 110 samples for Class Recall Cheque.\n",
      "Finished Class: Recall Cheque\n",
      "Data to Be Generated : 181\n",
      "Finished Class: Events\n",
      "Data to Be Generated : 181\n",
      "Warning: Model returned only 126 samples for Class Access Permission - MVD.\n",
      "Finished Class: Access Permission - MVD\n",
      "Data to Be Generated : 182\n",
      "Warning: Model returned only 100 samples for Class Receiving Old Cheques.\n",
      "Finished Class: Receiving Old Cheques\n",
      "Data to Be Generated : 184\n",
      "Warning: Model returned only 117 samples for Class Gym issues.\n",
      "Finished Class: Gym issues\n",
      "Data to Be Generated : 184\n",
      "Warning: Model returned only 105 samples for Class Extra Parking/Storage.\n",
      "Finished Class: Extra Parking/Storage\n",
      "Data to Be Generated : 184\n",
      "Finished Class: Careers\n",
      "Data to Be Generated : 184\n",
      "Warning: Model returned only 107 samples for Class Cheque Resubmission.\n",
      "Finished Class: Cheque Resubmission\n",
      "Data to Be Generated : 185\n",
      "Warning: Model returned only 98 samples for Class RO- Landscape Issues.\n",
      "Finished Class: RO- Landscape Issues\n",
      "Data to Be Generated : 185\n",
      "Finished Class: RO- Kids Area - Lack of Supervision\n",
      "Data to Be Generated : 185\n",
      "Warning: Model returned only 117 samples for Class Sports courts reservation.\n",
      "Finished Class: Sports courts reservation\n",
      "Data to Be Generated : 186\n",
      "Warning: Model returned only 120 samples for Class Gym.\n",
      "Finished Class: Gym\n",
      "Data to Be Generated : 187\n",
      "Finished Class: Handover - Finance\n",
      "Data to Be Generated : 187\n",
      "Warning: Model returned only 104 samples for Class Rent.\n",
      "Finished Class: Rent\n",
      "Data to Be Generated : 187\n",
      "Warning: Model returned only 141 samples for Class Retail Operation.\n",
      "Finished Class: Retail Operation\n",
      "Data to Be Generated : 187\n",
      "Warning: Model returned only 126 samples for Class Contractors Violation.\n",
      "Finished Class: Contractors Violation\n",
      "Data to Be Generated : 188\n",
      "Warning: Model returned only 92 samples for Class Access Permission - UTC.\n",
      "Finished Class: Access Permission - UTC\n",
      "Data to Be Generated : 188\n",
      "Finished Class: FM - Finance\n",
      "Data to Be Generated : 189\n",
      "Warning: Model returned only 120 samples for Class Signage.\n",
      "Finished Class: Signage\n",
      "Data to Be Generated : 189\n",
      "Warning: Model returned only 107 samples for Class Check Up Call.\n",
      "Finished Class: Check Up Call\n",
      "Data to Be Generated : 190\n",
      "Warning: Model returned only 89 samples for Class WhatsApp number.\n",
      "Finished Class: WhatsApp number\n",
      "Data to Be Generated : 190\n",
      "Finished Class: Emaar Misr application Feedback/suggestions\n",
      "                                     PROBLEM_CODE  \\\n",
      "0                                Reset App Device   \n",
      "1                                  Access Control   \n",
      "2                                  Access Control   \n",
      "3                                       Elevators   \n",
      "4                                       Elevators   \n",
      "...                                           ...   \n",
      "9342  Emaar Misr application Feedback/suggestions   \n",
      "9343  Emaar Misr application Feedback/suggestions   \n",
      "9344  Emaar Misr application Feedback/suggestions   \n",
      "9345  Emaar Misr application Feedback/suggestions   \n",
      "9346  Emaar Misr application Feedback/suggestions   \n",
      "\n",
      "                                        PROBLEM_SUMMARY  \n",
      "0     1.  Karim primary client reports app is locked...  \n",
      "1     1.  Client reported their access fob malfuncti...  \n",
      "2     2.  Omar, primary tenant, complains his newly ...  \n",
      "3     The elevator is stuck between floors, causing ...  \n",
      "4     Client reports elevator malfunctioning; doors ...  \n",
      "...                                                 ...  \n",
      "9342                      186.  App instability.  Abeer  \n",
      "9343                      187.  Poor performance.  Omar  \n",
      "9344                          188.  App freezes.  Rania  \n",
      "9345                      189.  Payment failure.  Nader  \n",
      "9346                 190.  QR code malfunctions.  Marwa  \n",
      "\n",
      "[9347 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have a DataFrame for storing the results\n",
    "result_df = pd.DataFrame(columns=['PROBLEM_CODE', 'PROBLEM_SUMMARY'])\n",
    "\n",
    "# Loop through each class in the list\n",
    "for Class in classes_To_generate[0]:\n",
    "    # Filter the examples for the current class\n",
    "    Examples = data_[data_['PROBLEM_CODE'] == Class]['PROBLEM_SUMMARY']\n",
    "    \n",
    "    # Calculate the number of synthetic samples needed\n",
    "    No_Samples_to_Generate = 200 - Examples.shape[0]\n",
    "    \n",
    "    print(f\"Data to Be Generated : {No_Samples_to_Generate}\")\n",
    "\n",
    "    if No_Samples_to_Generate <= 0 : \n",
    "        print(f\"{Class} Skipped Because it has suffienct data\")\n",
    "        continue\n",
    "        \n",
    "    Examples = Examples.sample(n=10, random_state=42)\n",
    "    \n",
    "    # Format the examples for the prompt\n",
    "    Examples_str = \"\\n\".join(f\"- {example}\" for example in Examples)\n",
    "    \n",
    "    # Create the prompt\n",
    "    Prompt = f'''You are a data augmentation assistant. Your task is to generate synthetic examples to balance classes in a dataset. The data consists of text samples, and your output should be similar in style, context, and tone to the provided examples.\n",
    "\n",
    "    ### Instructions:\n",
    "    1. Generate exactly {No_Samples_to_Generate} synthetic text examples for the class labeled: {Class}.\n",
    "    2. Use the following examples as references for the style, tone, and content:\n",
    "    {Examples_str}\n",
    "    3. Ensure the generated examples:\n",
    "    - Are unique and not verbatim copies of the examples.\n",
    "    - Are consistent with the context and subject matter of the examples.\n",
    "    - Avoid introducing irrelevant, offensive, or unrelated content.\n",
    "\n",
    "    ### Output Format:\n",
    "    - Provide a numbered list of exactly {No_Samples_to_Generate} unique synthetic examples for the specified class.\n",
    "    - Each example should be on a new line without numbering, and they should be clear and concise.\n",
    "\n",
    "    Start generating synthetic examples now. '''\n",
    "        \n",
    "    #Model Call\n",
    "\n",
    "    response = model.generate_content(Prompt).text \n",
    "   \n",
    "    # Split the response into individual examples based on new lines\n",
    "    generated_texts = response.splitlines()\n",
    "\n",
    "    if len(generated_texts) < No_Samples_to_Generate:\n",
    "        print(f\"Warning: Model returned only {len(generated_texts)} samples for Class {Class}.\")\n",
    "    \n",
    "    generated_texts = [text.strip() for text in generated_texts if text.strip()]\n",
    "    \n",
    "    # Create a new DataFrame for the generated data with correct class labels\n",
    "    new_data = pd.DataFrame({\n",
    "        'PROBLEM_CODE': [Class] * len(generated_texts),\n",
    "        'PROBLEM_SUMMARY': generated_texts\n",
    "    })\n",
    "    \n",
    "    # Concatenate the new data with the existing result_df\n",
    "    result_df = pd.concat([result_df, new_data], ignore_index=True)\n",
    "\n",
    "    print(f\"Finished Class: {Class}\")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROBLEM_CODE</th>\n",
       "      <th>PROBLEM_SUMMARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reset App Device</td>\n",
       "      <td>1.  Karim primary client reports app is locked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Access Control</td>\n",
       "      <td>1.  Client reported their access fob malfuncti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Access Control</td>\n",
       "      <td>2.  Omar, primary tenant, complains his newly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elevators</td>\n",
       "      <td>The elevator is stuck between floors, causing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elevators</td>\n",
       "      <td>Client reports elevator malfunctioning; doors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9342</th>\n",
       "      <td>Emaar Misr application Feedback/suggestions</td>\n",
       "      <td>186.  App instability.  Abeer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9343</th>\n",
       "      <td>Emaar Misr application Feedback/suggestions</td>\n",
       "      <td>187.  Poor performance.  Omar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9344</th>\n",
       "      <td>Emaar Misr application Feedback/suggestions</td>\n",
       "      <td>188.  App freezes.  Rania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9345</th>\n",
       "      <td>Emaar Misr application Feedback/suggestions</td>\n",
       "      <td>189.  Payment failure.  Nader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9346</th>\n",
       "      <td>Emaar Misr application Feedback/suggestions</td>\n",
       "      <td>190.  QR code malfunctions.  Marwa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9347 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     PROBLEM_CODE  \\\n",
       "0                                Reset App Device   \n",
       "1                                  Access Control   \n",
       "2                                  Access Control   \n",
       "3                                       Elevators   \n",
       "4                                       Elevators   \n",
       "...                                           ...   \n",
       "9342  Emaar Misr application Feedback/suggestions   \n",
       "9343  Emaar Misr application Feedback/suggestions   \n",
       "9344  Emaar Misr application Feedback/suggestions   \n",
       "9345  Emaar Misr application Feedback/suggestions   \n",
       "9346  Emaar Misr application Feedback/suggestions   \n",
       "\n",
       "                                        PROBLEM_SUMMARY  \n",
       "0     1.  Karim primary client reports app is locked...  \n",
       "1     1.  Client reported their access fob malfuncti...  \n",
       "2     2.  Omar, primary tenant, complains his newly ...  \n",
       "3     The elevator is stuck between floors, causing ...  \n",
       "4     Client reports elevator malfunctioning; doors ...  \n",
       "...                                                 ...  \n",
       "9342                      186.  App instability.  Abeer  \n",
       "9343                      187.  Poor performance.  Omar  \n",
       "9344                          188.  App freezes.  Rania  \n",
       "9345                      189.  Payment failure.  Nader  \n",
       "9346                 190.  QR code malfunctions.  Marwa  \n",
       "\n",
       "[9347 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"Augmented_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df = pd.concat([a_df, result_df1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROBLEM_CODE</th>\n",
       "      <th>PROBLEM_SUMMARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neighbor Noise</td>\n",
       "      <td>client name Gamila call us The client complain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neighbor Noise</td>\n",
       "      <td>the client complains many times about his Neig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neighbor Noise</td>\n",
       "      <td>the client complains that his neighbor in Mara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neighbor Noise</td>\n",
       "      <td>Caller Alia  Request  Client is complaining fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neighbor Noise</td>\n",
       "      <td>Who calledMoheb What did they request The cust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26806</th>\n",
       "      <td>RO- Events Parking Issues</td>\n",
       "      <td>Caller:  Saif, Request:  Lost parking ticket, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26807</th>\n",
       "      <td>RO- Events Parking Issues</td>\n",
       "      <td>Caller:  Hend, Request:  Parking gate malfunct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26808</th>\n",
       "      <td>RO- Events Parking Issues</td>\n",
       "      <td>Caller:  Ahmad, Request:  Request for a design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26809</th>\n",
       "      <td>RO- Events Parking Issues</td>\n",
       "      <td>Caller:  Lamia, Request:  Need for improved ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26810</th>\n",
       "      <td>RO- Events Parking Issues</td>\n",
       "      <td>Caller:  Wael, Request:  Double-parked vehicle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26811 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    PROBLEM_CODE  \\\n",
       "0                 Neighbor Noise   \n",
       "1                 Neighbor Noise   \n",
       "2                 Neighbor Noise   \n",
       "3                 Neighbor Noise   \n",
       "4                 Neighbor Noise   \n",
       "...                          ...   \n",
       "26806  RO- Events Parking Issues   \n",
       "26807  RO- Events Parking Issues   \n",
       "26808  RO- Events Parking Issues   \n",
       "26809  RO- Events Parking Issues   \n",
       "26810  RO- Events Parking Issues   \n",
       "\n",
       "                                         PROBLEM_SUMMARY  \n",
       "0      client name Gamila call us The client complain...  \n",
       "1      the client complains many times about his Neig...  \n",
       "2      the client complains that his neighbor in Mara...  \n",
       "3      Caller Alia  Request  Client is complaining fr...  \n",
       "4      Who calledMoheb What did they request The cust...  \n",
       "...                                                  ...  \n",
       "26806  Caller:  Saif, Request:  Lost parking ticket, ...  \n",
       "26807  Caller:  Hend, Request:  Parking gate malfunct...  \n",
       "26808  Caller:  Ahmad, Request:  Request for a design...  \n",
       "26809  Caller:  Lamia, Request:  Need for improved ma...  \n",
       "26810  Caller:  Wael, Request:  Double-parked vehicle...  \n",
       "\n",
       "[26811 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df.to_csv(\"a_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = a_df['PROBLEM_CODE'].value_counts()\n",
    "\n",
    "# Filter for classes with fewer than 200 samples\n",
    "classes_less_than_200 = class_counts[class_counts < 200].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Traffic issues MSA',\n",
       " 'RO- Noise - Private workers',\n",
       " 'RO- Events Parking Issues']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_less_than_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data to Be Generated : 21\n",
      "Finished Class: Traffic issues MSA\n",
      "Data to Be Generated : 21\n",
      "Finished Class: RO- Noise - Private workers\n",
      "Data to Be Generated : 31\n",
      "Finished Class: RO- Events Parking Issues\n",
      "                 PROBLEM_CODE  \\\n",
      "0          Traffic issues MSA   \n",
      "1          Traffic issues MSA   \n",
      "2          Traffic issues MSA   \n",
      "3          Traffic issues MSA   \n",
      "4          Traffic issues MSA   \n",
      "..                        ...   \n",
      "68  RO- Events Parking Issues   \n",
      "69  RO- Events Parking Issues   \n",
      "70  RO- Events Parking Issues   \n",
      "71  RO- Events Parking Issues   \n",
      "72  RO- Events Parking Issues   \n",
      "\n",
      "                                      PROBLEM_SUMMARY  \n",
      "0   Caller Omar, Request: Excessive traffic on Elm...  \n",
      "1   Caller Hala, Request:  Traffic jam near the ho...  \n",
      "2   Caller Khaled, Request:  Construction work cau...  \n",
      "3   Caller Amira, Request:  Recurring traffic cong...  \n",
      "4   Caller Samir, Request:  Heavy traffic due to a...  \n",
      "..                                                ...  \n",
      "68  Caller:  Saif, Request:  Lost parking ticket, ...  \n",
      "69  Caller:  Hend, Request:  Parking gate malfunct...  \n",
      "70  Caller:  Ahmad, Request:  Request for a design...  \n",
      "71  Caller:  Lamia, Request:  Need for improved ma...  \n",
      "72  Caller:  Wael, Request:  Double-parked vehicle...  \n",
      "\n",
      "[73 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have a DataFrame for storing the results\n",
    "result_df1 = pd.DataFrame(columns=['PROBLEM_CODE', 'PROBLEM_SUMMARY'])\n",
    "\n",
    "# Loop through each class in the list\n",
    "for Class in classes_less_than_200:\n",
    "    # Filter the examples for the current class\n",
    "    Examples = a_df[a_df['PROBLEM_CODE'] == Class]['PROBLEM_SUMMARY']\n",
    "    \n",
    "    # Calculate the number of synthetic samples needed\n",
    "    No_Samples_to_Generate = 200 - Examples.shape[0]\n",
    "    \n",
    "    print(f\"Data to Be Generated : {No_Samples_to_Generate}\")\n",
    "\n",
    "    if No_Samples_to_Generate <= 0 : \n",
    "        print(f\"{Class} Skipped Because it has suffienct data\")\n",
    "        continue\n",
    "        \n",
    "    Examples = Examples.sample(n=10, random_state=42)\n",
    "    \n",
    "    # Format the examples for the prompt\n",
    "    Examples_str = \"\\n\".join(f\"- {example}\" for example in Examples)\n",
    "    \n",
    "    # Create the prompt\n",
    "    Prompt = f'''You are a data augmentation assistant. Your task is to generate synthetic examples to balance classes in a dataset. The data consists of text samples, and your output should be similar in style, context, and tone to the provided examples.\n",
    "\n",
    "    ### Instructions:\n",
    "    1. Generate exactly {No_Samples_to_Generate} synthetic text examples for the class labeled: {Class}.\n",
    "    2. Use the following examples as references for the style, tone, and content:\n",
    "    {Examples_str}\n",
    "    3. Ensure the generated examples:\n",
    "    - Are unique and not verbatim copies of the examples.\n",
    "    - Are consistent with the context and subject matter of the examples.\n",
    "    - Avoid introducing irrelevant, offensive, or unrelated content.\n",
    "\n",
    "    ### Output Format:\n",
    "    - Provide a numbered list of exactly {No_Samples_to_Generate} unique synthetic examples for the specified class.\n",
    "    - Each example should be on a new line without numbering, and they should be clear and concise.\n",
    "\n",
    "    Start generating synthetic examples now. '''\n",
    "        \n",
    "    #Model Call\n",
    "\n",
    "    response = model.generate_content(Prompt).text \n",
    "   \n",
    "    # Split the response into individual examples based on new lines\n",
    "    generated_texts = response.splitlines()\n",
    "\n",
    "    if len(generated_texts) < No_Samples_to_Generate:\n",
    "        print(f\"Warning: Model returned only {len(generated_texts)} samples for Class {Class}.\")\n",
    "    \n",
    "    generated_texts = [text.strip() for text in generated_texts if text.strip()]\n",
    "    \n",
    "    # Create a new DataFrame for the generated data with correct class labels\n",
    "    new_data = pd.DataFrame({\n",
    "        'PROBLEM_CODE': [Class] * len(generated_texts),\n",
    "        'PROBLEM_SUMMARY': generated_texts\n",
    "    })\n",
    "    \n",
    "    # Concatenate the new data with the existing result_df\n",
    "    result_df1 = pd.concat([result_df1, new_data], ignore_index=True)\n",
    "\n",
    "    print(f\"Finished Class: {Class}\")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(result_df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROBLEM_CODE</th>\n",
       "      <th>PROBLEM_SUMMARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carpentry</td>\n",
       "      <td>1.  Loose floorboard in the kitchen causing a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>General Queries</td>\n",
       "      <td>1. Client inquired about the availability of p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RO- Parking Issues</td>\n",
       "      <td>1. Resident complains about ongoing illegal pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Swimming Pool</td>\n",
       "      <td>1. Client reports the swimming pool at Palm Vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swimming Pool</td>\n",
       "      <td>2. Urgent: The children's wading pool at the O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Fiber Cable</td>\n",
       "      <td>Fiber optic cable failure causing significant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>Fiber Cable</td>\n",
       "      <td>Client is reporting total loss of connectivity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Fiber Cable</td>\n",
       "      <td>Fiber cable breakage detected; requires immedi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Fiber Cable</td>\n",
       "      <td>Investigate fiber cable; intermittent connecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Fiber Cable</td>\n",
       "      <td>Fiber cable malfunction; needs immediate atten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PROBLEM_CODE                                    PROBLEM_SUMMARY\n",
       "0             Carpentry  1.  Loose floorboard in the kitchen causing a ...\n",
       "1       General Queries  1. Client inquired about the availability of p...\n",
       "2    RO- Parking Issues  1. Resident complains about ongoing illegal pa...\n",
       "3         Swimming Pool  1. Client reports the swimming pool at Palm Vi...\n",
       "4         Swimming Pool  2. Urgent: The children's wading pool at the O...\n",
       "..                  ...                                                ...\n",
       "322         Fiber Cable  Fiber optic cable failure causing significant ...\n",
       "323         Fiber Cable  Client is reporting total loss of connectivity...\n",
       "324         Fiber Cable  Fiber cable breakage detected; requires immedi...\n",
       "325         Fiber Cable  Investigate fiber cable; intermittent connecti...\n",
       "326         Fiber Cable  Fiber cable malfunction; needs immediate atten...\n",
       "\n",
       "[327 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME = \"shit\"\n",
    "Examples = {\"The order was supposed to arrive last week, but it hasn't been delivered yet.\",\"The package tracking status shows 'in transit' for over a month.\",\"Customer is frustrated due to delayed delivery of their order.\"}\n",
    "No_Samples = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''You are a data augmentation assistant. Your task is to generate synthetic examples to balance classes in a dataset. The data consists of text samples, and your output should be similar in style, context, and tone to the provided examples.\n",
    "\n",
    "### Instructions:\n",
    "1. Generate synthetic text examples for the class labeled: {CLASS_NAME}.\n",
    "2. Use the following examples as references for the style, tone, and content:\n",
    "   {Examples}\n",
    "3. Ensure the generated examples:\n",
    "   - Are unique and not verbatim copies of the examples.\n",
    "   - Are consistent with the context and subject matter of the examples.\n",
    "   - Avoid introducing irrelevant, offensive, or unrelated content.\n",
    "\n",
    "### Output Format:\n",
    "- Provide a numbered list of {No_Samples_to_Generate} unique synthetic examples for the specified class. \n",
    "- Each example should be on a new line without numbering, and they should be clear and concise.\n",
    "\n",
    "Start generating synthetic examples now.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a data augmentation assistant. Your task is to generate synthetic examples to balance classes in a dataset. The data consists of text samples, and your output should be similar in style, context, and tone to the provided examples.\\n\\n### Instructions:\\n1. Generate synthetic text examples for the class labeled: shit.\\n2. Use the following examples as references for the style, tone, and content:\\n   {\"The package tracking status shows \\'in transit\\' for over a month.\", \\'Customer is frustrated due to delayed delivery of their order.\\', \"The order was supposed to arrive last week, but it hasn\\'t been delivered yet.\"}\\n3. Ensure the generated examples:\\n   - Are unique and not verbatim copies of the examples.\\n   - Are consistent with the context and subject matter of the examples.\\n   - Avoid introducing irrelevant, offensive, or unrelated content.\\n\\n### Output Format:\\n- Provide a numbered list of 20 unique synthetic examples for the specified class. \\n- Each example should be on a new line without numbering, and they should be clear and concise.\\n\\nStart generating synthetic examples now.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
